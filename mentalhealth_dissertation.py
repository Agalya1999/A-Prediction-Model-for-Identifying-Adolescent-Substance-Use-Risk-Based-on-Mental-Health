# -*- coding: utf-8 -*-
"""MentalHealth_Dissertation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wshRaJpbjGUXF_MJJbgPIYSuFdVMLmbe
"""

!pip install researchpy
!pip install pandas numpy scikit-learn imbalanced-learn seaborn
!pip install shap

import pandas as pd
import numpy as np
import seaborn as sns
import researchpy
from matplotlib import pyplot as plt
from google.colab import drive
#drive.mount('/content/drive')
from scipy.stats import chi2_contingency
from sklearn.impute import KNNImputer
from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTEN
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import RepeatedKFold, cross_validate
from sklearn.metrics import confusion_matrix
from statistics import mean
import shap
import copy

pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)

s5_cfile = '/content/mcs5_interview_cm.csv'
s6_cfile = '/content/mcs6_interview_cm.csv'
s7_cfile = '/content/mcs7_interview_cm.csv'

s5_pfile = '/content/mcs5_interview_p.csv'
s6_pfile = '/content/mcs6_interview_p.csv'
s7_pfile = '/content/mcs7_interview_p.csv'

#s6_cogfile = '/content/drive/MyDrive/Mental_health_dataset/mcs6_interview_cognitive.csv'
#s7_qfile = '/content/drive/MyDrive/Mental_health_dataset/mcs7_interview_qualifications.csv'

s5_cm = pd.read_csv(s5_cfile)
s6_cm = pd.read_csv(s6_cfile)
s7_cm = pd.read_csv(s7_cfile)

s5_p = pd.read_csv(s5_pfile)
s6_p = pd.read_csv(s6_pfile)
s7_p = pd.read_csv(s7_pfile)

#s5_tcm = pd.read_csv(s6_cogfile)
#s7_qcm = pd.read_csv(s7_qfile)

s5_cm.columns

"""#Cleaning the Datasets
Creating Cohort and Person ID's to merge dataframes on and ensure continuity


"""

s5_cm["Cohort_ID"] = s5_cm["MCSID"] + s5_cm["ECNUM00"].astype(str)
s6_cm["Cohort_ID"] = s6_cm["MCSID"] + s6_cm["FCNUM00"].astype(str)
s7_cm["Cohort_ID"] = s7_cm["MCSID"] + s7_cm["GCNUM00"].astype(str)
s5_cm["Merge_ID"] = s5_cm["MCSID"] + s5_cm["ECNUM00"].astype(str)
s6_cm["Merge_ID"] = s6_cm["MCSID"] + s6_cm["FCNUM00"].astype(str)
s7_cm["Merge_ID"] = s7_cm["MCSID"] + s7_cm["GCNUM00"].astype(str)

s5_p["Person_ID"] = s5_p["MCSID"] + s5_p["EPNUM00"].astype(str)
s6_p["Person_ID"] = s6_p["MCSID"] + s6_p["FPNUM00"].astype(str)
s7_p["Person_ID"] = s7_p["MCSID"] + s7_p["GPNUM00"].astype(str)

s6_p.columns

s5_cm['Cohort_ID'].head()

s6_cm['Cohort_ID'].head()

s7_cm['Cohort_ID'].head()

"""Renaming the columns to make them easier tor read


"""

#Renaming all the variables for each of the tables, making it easier to read the datasets
s5_cm.columns=['s5_MCSID','s5_ECNUM','s5_friends_smoke','s5_tried_cigarette','s5_friends_drink','s5_tried_alcohol','s5_alcohol_freq_12mo','s5_alcohol_freq_4wk','heavy_drinking','Cohort_ID', "Merge_ID"]

s6_cm.columns =['s6_MCSID','s6_FCNUM','s6_Sex','s6_SmokeFreq_Cigarettes','s6_SmokeFreq_E_Cigarettes','s6_SmokeFreq_Friends_Cigarettes','s6_Ever_Alcoholic_Drink','s6_AlcoholFreq_12mo','s6_AlcoholFreq_4wk',
                 's6_Ever_5plus_Alcohol','s6_AlcoholFreq_5plus_12mo','s6_Friends_Drink_Alcohol','s6_Drug_Cannabis','s6_Drug_Other_Illegal','s6_SmokeFreq_Cannabis','s6_Friends_Illegal_Drugs',
                 's6_Feelings_Miserable','s6_Feelings_NoEnjoyment','s6_Feelings_Tired','s6_Feelings_Restless','s6_Feelings_NoGood','s6_Feelings_Cried','s6_Feelings_Concentration','s6_Feelings_HateMyself',
                 's6_Feelings_BadPerson','s6_Feelings_Lonely','s6_Feelings_Unloved','s6_Feelings_Inferior','s6_Feelings_Wrong', 'Cohort_ID', "Merge_ID"]

s7_cm.columns =['s7_MCSID','s7_GCNUM','s7_SDQ1','s7_SDQ2','s7_SDQ3','s7_SDQ4','s7_SDQ5','s7_SDQ6','s7_SDQ7','s7_SDQ8','s7_SDQ9','s7_SDQ10','s7_SDQ11','s7_SDQ12','s7_SDQ13','s7_SDQ14','s7_SDQ15',
                's7_SDQ16','s7_SDQ17','s7_SDQ18','s7_SDQ19','s7_SDQ20','s7_SDQ21','s7_SDQ22','s7_SDQ23','s7_SDQ24','s7_SDQ25','s7_Feel_Depressed_Frequency','s7_Feel_Hopeless_Frequency','s7_Feel_Restless_Frequency','s7_Feel_Effort_Frequency',
                's7_Feel_Worthless_Frequency','s7_Feel_Nervous_Frequency','s7_Doctor_Diagnosed_Depression_Anxiety','s7_Currently_Treated_Depression_Anxiety','s7_Ever_Treated_Depression_Anxiety','s7_Self_Harm_Cut_Stabbed','s7_Self_Harm_Burned',
                's7_Self_Harm_Bruised','s7_Self_Harm_Overdose','s7_Self_Harm_Pulled_Hair','s7_Self_Harm_Other','s7_Smoking_Status','s7_Vaping_Status','s7_Ever_Alcoholic_Drink','s7_Age_First_Alcoholic_Drink','s7_AlcoholFreq_12mo','s7_AlcoholFreq_4wk',
                's7_Ever_5plus_Alcohol','s7_AlcoholFreq_5plus_12mo','s7_Ever_Taken_Cannabis','s7_Ever_Taken_Cocaine','s7_Ever_Taken_Acid','s7_Ever_Taken_Ecstasy','s7_Ever_Taken_Speed','s7_Ever_Taken_Semeron','s7_Ever_Taken_Ketamine','s7_Ever_Taken_Mephedrone',
                's7_Ever_Taken_Psychoactive_Substances','s7_PastYear_Cannabis_Freq','s7_PastYear_Cocaine_Freq','s7_PastYear_Acid_Freq','s7_PastYear_Ecstasy_Freq','s7_PastYear_Speed_Freq','s7_PastYear_Semeron_Freq','s7_PastYear_Ketamine_Freq','s7_PastYear_Mephedrone_Freq',
                's7_PastYear_Psychoactive_Freq','Cohort_ID', "Merge_ID"]

s5_p.columns=['s5_MCSID','s5_EPNUM','s5_Tobacco_None_P','s5_Tobacco_Cigarettes_P','s5_Tobacco_Roll_Ups_P','s5_Tobacco_Cigars_P','s5_Tobacco_Pipe_P','s5_Tobacco_Chewing_P','s5_Tobacco_Other_P','s5_Tobacco_Refused_P','s5_Tobacco_Dont_Know','s5_Cigarettes_Per_Day','s5_Ever_Smoked_Tobacco','s5_Felt_Depressed_Freq','s5_Felt_Hopeless_Freq','s5_Felt_Restless_Freq_P',
              's5_Felt_Effort_Freq_P','s5_Felt_Worthless_Freq_P','s5_Felt_Nervous_Freq_P','s5_Diagnosed_Depression_Anxiety_P','s5_Currently_Treated_Depression_Anxiety_P','s5_Alcohol_Frequency_P','s5_Standard_Drinks_Per_Day_P','s5_Relative_Concerned_Drinking_P','Person_ID']

s6_p.columns=['s6_MCSID','s6_FPNUM','s6_Smoking_None_P','s6_Smoking_Cigarettes_P','s6_Smoking_Roll_Ups_P','s6_Smoking_Cigars_P','s6_Smoking_Pipe_P','s6_Smoking_Chewing_P','s6_Smoking_Other_P','s6_Cigarettes_Per_Day_P','s6_Felt_Depressed_Freq_P','s6_Felt_Hopeless_Freq_P','s6_Felt_Restless_Freq_P',
              's6_Felt_Effort_Freq_P','s6_Felt_Worthless_Freq_P','s6_Felt_Nervous_Freq_P','s6_Diagnosed_Depression_Anxiety_P','s6_Currently_Treated_Depression_Anxiety_P','s6_Alcohol_Frequency_P','s6_Standard_Drinks_Per_Day_P','s6_Not_Able_Stop_Drinking_P','s6_Failed_Expectations_Drinking_P',
              's6_Relative_Concerned_Drinking_P','s6_Used_Recreational_Drugs_P','Person_ID']

"""Turning all -1, -8 and -9 values into Nan for the Exploratory data stage

These Nan values will need to be further addressed at the modelling stage (Remove columns, rows or use KNN/LR to fill in the Nan values)
"""

#Change all -1 (Not Applicable/Missing Data) to NaN values
Ns5cm = s5_cm.replace([-1, -8, -9], np.NaN)
Ns6cm = s6_cm.replace([-1, -8, -9], np.NaN)
Ns7cm = s7_cm.replace([-1, -8, -9], np.NaN)


Ns5p = s5_p.replace([-1, -8, -9], np.NaN)
Ns6p = s6_p.replace([-1, -8, -9], np.NaN)

#Checking each dataframe for Null Variables
print('Sweep 5 Cohort Member Dataset: {}'.format(Ns5cm.isnull().any().any()))
print('Sweep 6 Cohort Member Dataset: {}'.format(Ns6cm.isnull().any().any()))
print('Sweep 7 Cohort Member Dataset: {}'.format(Ns7cm.isnull().any().any()))

print('Sweep 5 Parent Dataset: {}'.format(Ns5p.isnull().any().any()))
print('Sweep 6 Parent Dataset: {}'.format(Ns6p.isnull().any().any()))

merge_cm = Ns5cm.merge(Ns6cm, on='Merge_ID')
all_cm = merge_cm.merge(Ns7cm, on='Merge_ID') #9184 values

merge_parent = Ns5p.merge(Ns6p, on='Person_ID') #17190 values

all_cm = all_cm.drop_duplicates(subset=['Cohort_ID'], keep='first')

all_cm.head()

all_cm = all_cm.reset_index()

all_cm = all_cm.drop(columns=['s7_Ever_Treated_Depression_Anxiety'])

all_cm.head()

self_harm_0 = all_cm.filter(['s7_Self_Harm_Cut_Stabbed','s7_Self_Harm_Burned','s7_Self_Harm_Bruised','s7_Self_Harm_Overdose','s7_Self_Harm_Pulled_Hair','s7_Self_Harm_Other','Cohort_ID'],axis=1)
self_harm = self_harm_0.replace([1,2,3,4,5],[1,0,0,0,0])

self_harm['self_harm_score'] = self_harm.apply(lambda row:(row.s7_Self_Harm_Cut_Stabbed+row.s7_Self_Harm_Burned+row.s7_Self_Harm_Bruised+row.s7_Self_Harm_Overdose+row.s7_Self_Harm_Pulled_Hair+row.s7_Self_Harm_Other),axis=1)

self_harm['self_harm_score'].value_counts()

self_harm_conditions = [(self_harm['self_harm_score']==0), (self_harm['self_harm_score']>0)]
self_harm_banding = ['Normal','Abnormal']
self_harm['self_harm_banding'] = np.select(self_harm_conditions, self_harm_banding)

self_harm['self_harm_banding'].value_counts()

Self_Harm_1 = self_harm.filter(['self_harm_banding','Cohort_ID'],axis=1)

Self_Harm_1.value_counts

"""#Independent Variables

* SDQ Scores
* K6 Scores
* Total Score
"""

SDQ_0 = all_cm.filter(['s7_SDQ1', 's7_SDQ2', "s7_SDQ3", 's7_SDQ4', 's7_SDQ5', 's7_SDQ6', 's7_SDQ7', 's7_SDQ8', 's7_SDQ9', 's7_SDQ10', 's7_SDQ11', 's7_SDQ12', 's7_SDQ13', 's7_SDQ14', 's7_SDQ15', 's7_SDQ16',
         's7_SDQ17', 's7_SDQ18', 's7_SDQ19', 's7_SDQ20', 's7_SDQ21', 's7_SDQ22', 's7_SDQ23', 's7_SDQ24', 's7_SDQ25', 'Cohort_ID'], axis=1)
SDQ = SDQ_0.replace([1, 2, 3], [0, 1, 2])

SDQ['SDQ_Score'] = SDQ.apply(lambda row: (row.s7_SDQ5 + row.s7_SDQ7 + row.s7_SDQ12 + row.s7_SDQ18 + row.s7_SDQ22 + row.s7_SDQ2 + row.s7_SDQ10 + row.s7_SDQ15 + row.s7_SDQ21 + row.s7_SDQ25 + row.s7_SDQ3
                            + row.s7_SDQ8 + row.s7_SDQ13 + row.s7_SDQ16 + row.s7_SDQ24 + row.s7_SDQ6 + row.s7_SDQ11 + row.s7_SDQ14 + row.s7_SDQ19 + row.s7_SDQ23) - (row.s7_SDQ1 + row.s7_SDQ4
                            + row.s7_SDQ9 + row.s7_SDQ17 + row.s7_SDQ20), axis=1)

SDQ_Conditions = [(SDQ['SDQ_Score'] <= 13),
                  (SDQ['SDQ_Score'] > 13) & (SDQ['SDQ_Score'] <= 16),
                  (SDQ['SDQ_Score'] > 16)]

SDQ_Banding = ['Normal', 'Borderline', 'Abnormal']

SDQ['SDQ_Banding'] = np.select(SDQ_Conditions, SDQ_Banding)

"""0-13 = Normal 14-16 = Borderline 17-40 = Abnormal Scores of 0-14 is close to average, Scores 15-17 is slight raised, Scores 18-19 is High, Scores 20-40 is Very High"""

SDQ['SDQ_Banding'].value_counts()

K6_0 = all_cm.filter([ 's7_Feel_Depressed_Frequency', 's7_Feel_Hopeless_Frequency', 's7_Feel_Restless_Frequency', 's7_Feel_Effort_Frequency', 's7_Feel_Worthless_Frequency','s7_Feel_Nervous_Frequency', 'Cohort_ID'], axis=1)
K6 = K6_0.replace([1, 2, 3, 4, 5, 6, 7, 8], [4, 3, 2, 1, 0, 0, 0, 0])

K6['K6_Score'] = K6.apply(lambda row: row.s7_Feel_Depressed_Frequency + row.s7_Feel_Hopeless_Frequency + row.s7_Feel_Restless_Frequency + row.s7_Feel_Worthless_Frequency + row.s7_Feel_Nervous_Frequency, axis=1)

k6_Conditions = [(K6['K6_Score'] <=12),
                 (K6['K6_Score'] > 12)]

K6_Banding = ['Normal', 'Abnormal']

K6['K6_Banding'] = np.select(k6_Conditions, K6_Banding)

K6['K6_Banding'].value_counts()

Diagnosis_0 = all_cm.filter(['s7_Doctor_Diagnosed_Depression_Anxiety','Cohort_ID'],axis=1)

Diagnosis = Diagnosis_0.replace([2, 3, 4, 5], [0, 0, 0, 0])

Diagnosis['s7_Doctor_Diagnosed_Depression_Anxiety'].value_counts()

SDQ_K6 = SDQ.merge(K6, on='Cohort_ID')
Depression_SDQ_K6 = SDQ_K6.merge(Diagnosis, on='Cohort_ID')
InDependent_Var = Depression_SDQ_K6.merge(Self_Harm_1, on='Cohort_ID')

IDV_0 = InDependent_Var[['SDQ_Banding', 'K6_Banding','s7_Doctor_Diagnosed_Depression_Anxiety','self_harm_banding','Cohort_ID']]

IDV = IDV_0.replace(['Normal', 'Borderline', 'Abnormal'], [0, 0.5, 1])
IDV = IDV.astype({'SDQ_Banding': float,'K6_Banding' : float,'self_harm_banding':float})
IDV['Total_Score_DV'] = IDV.apply(lambda row: row.SDQ_Banding + row.K6_Banding + row.s7_Doctor_Diagnosed_Depression_Anxiety + row.self_harm_banding, axis=1)

IDV_Conditions = [(IDV['Total_Score_DV'] <= 0.5),
                 (IDV['Total_Score_DV'] > 0.5)]

IDV_Banding = ['Normal','Abnormal']

IDV['Final_Banding'] = np.select(IDV_Conditions, IDV_Banding)

IDV['Final_Banding'].value_counts()

IDV.columns

all_cm.s6_Sex.head()

all = all_cm.merge(IDV, on ='Cohort_ID')
female = all[all['s6_Sex'] == 2]
male = all[all['s6_Sex'] == 1]

all.Total_Score_DV.value_counts()

"""#Exploratory Data Analysis

Alcohol
"""

all_cm['s7_PastYear_Cannabis_Freq'].replace([1, 2, 3, 4, 5,6,7,8], [1, 2, 3, 4, 0, 0, 0, 0])
all_cm['s7_PastYear_Cocaine_Freq'].replace([1, 2, 3, 4, 5,6,7,8], [1, 2, 3, 4, 0, 0, 0, 0])
all_cm['s7_PastYear_Acid_Freq'].replace([1, 2, 3, 4, 5,6,7,8], [1, 2, 3, 4, 0, 0, 0, 0])
all_cm['s7_PastYear_Ecstasy_Freq'].replace([1, 2, 3, 4, 5,6,7,8], [1, 2, 3, 4, 0, 0, 0, 0])
all_cm['s7_PastYear_Speed_Freq'].replace([1, 2, 3, 4, 5,6,7,8], [1, 2, 3, 4, 0, 0, 0, 0])
all_cm['s7_PastYear_Semeron_Freq'].replace([1, 2, 3, 4, 5,6,7,8], [1, 2, 3, 4, 0, 0, 0, 0])
all_cm['s7_PastYear_Ketamine_Freq'].replace([1, 2, 3, 4, 5,6,7,8], [1, 2, 3, 4, 0, 0, 0, 0])
all_cm['s7_PastYear_Mephedrone_Freq'].replace([1, 2, 3, 4, 5,6,7,8], [1, 2, 3, 4, 0, 0, 0, 0])
all_cm['s7_PastYear_Psychoactive_Freq'].replace([1, 2, 3, 4, 5,6,7,8], [1, 2, 3, 4, 0, 0, 0, 0])
all_cm['s5_alcohol_freq_12mo'].replace([1,2,3,4,5,6,7],[0,1,2,3,4,5,6])
all_cm['s5_alcohol_freq_4wk'].replace([1,2,3,4,5,6,7],[0,1,2,3,4,5,6])

all_cm['s7_PastYear_Drug'] = all_cm[['s7_PastYear_Cannabis_Freq', 's7_PastYear_Cocaine_Freq', 's7_PastYear_Acid_Freq',
                                     's7_PastYear_Ecstasy_Freq', 's7_PastYear_Speed_Freq', 's7_PastYear_Semeron_Freq',
                                     's7_PastYear_Ketamine_Freq', 's7_PastYear_Mephedrone_Freq', 's7_PastYear_Psychoactive_Freq']].sum(axis=1, skipna=True)

All_drug = all_cm[['s5_friends_smoke','s5_tried_cigarette', 's5_friends_drink', 's5_tried_alcohol',
       's5_alcohol_freq_12mo', 's5_alcohol_freq_4wk', 'heavy_drinking', 's6_Sex','s6_SmokeFreq_Cigarettes', 's6_SmokeFreq_E_Cigarettes',
       's6_SmokeFreq_Friends_Cigarettes', 's6_Ever_Alcoholic_Drink','s6_AlcoholFreq_12mo', 's6_AlcoholFreq_4wk',
       's6_Ever_5plus_Alcohol', 's6_AlcoholFreq_5plus_12mo','s6_Friends_Drink_Alcohol', 's6_Drug_Cannabis',
       's6_Drug_Other_Illegal', 's6_SmokeFreq_Cannabis','s6_Friends_Illegal_Drugs', 's7_Smoking_Status', 's7_Vaping_Status', 's7_Ever_Alcoholic_Drink',
       's7_Age_First_Alcoholic_Drink', 's7_AlcoholFreq_12mo', 's7_AlcoholFreq_4wk', 's7_Ever_5plus_Alcohol',
       's7_AlcoholFreq_5plus_12mo', 's7_Ever_Taken_Cannabis', 's7_Ever_Taken_Cocaine', 's7_Ever_Taken_Acid',
       's7_Ever_Taken_Ecstasy', 's7_Ever_Taken_Speed','s7_Ever_Taken_Semeron', 's7_Ever_Taken_Ketamine',
       's7_Ever_Taken_Mephedrone','s7_Ever_Taken_Psychoactive_Substances','s7_PastYear_Drug','Cohort_ID' ]]

new_column_names = {'s6_Sex': 'Parents_alcohol'}

All_drug.rename(columns=new_column_names, inplace=True)

DV1 = IDV.merge(All_drug, on='Cohort_ID')

DV1.columns

def check_score_perc(df, column1, column2, value):
  score = df[df[column1] == value]
  score_perc = 100 * score[column2].value_counts() / len(score[column2])
  return score_perc

def check_band_perc(df, column1, column2, Band):
  Banding = df[df[column1] == Band]
  Band_perc = Banding[column2].value_counts() / Banding[column2].value_counts().sum() * 100
  return Band_perc

"""#Tried Cigarette"""

Tried_cigarette = DV1[['s5_tried_cigarette', 'Final_Banding', 'Cohort_ID']]
Tried_cigarette_0 = Tried_cigarette[~Tried_cigarette['Final_Banding'].str.contains('Normal')]
tpfreq1 = Tried_cigarette_0.groupby(['s5_tried_cigarette', 'Final_Banding']).size()
tpfreq1.plot.bar('s5_tried_cigarette','Final_Banding')

print(check_score_perc(Tried_cigarette, 's5_tried_cigarette', 'Final_Banding', 1))
print(check_score_perc(Tried_cigarette, 's5_tried_cigarette', 'Final_Banding', 2))
print(check_band_perc(Tried_cigarette, 'Final_Banding', 's5_tried_cigarette', 'Normal'))
print(check_band_perc(Tried_cigarette, 'Final_Banding', 's5_tried_cigarette', 'Abnormal'))

s5_tried_alcohol = DV1[['s5_tried_alcohol', 'Final_Banding', 'Cohort_ID']]
s5_tried_alcohol_0 = s5_tried_alcohol[~s5_tried_alcohol['Final_Banding'].str.contains('Normal')]
tpfreq2 = s5_tried_alcohol_0.groupby(['s5_tried_alcohol', 'Final_Banding']).size()
tpfreq2.plot.bar('s5_tried_alcohol','Final_Banding')

print(check_score_perc(s5_tried_alcohol, 's5_tried_alcohol', 'Final_Banding', 1))
print(check_score_perc(s5_tried_alcohol, 's5_tried_alcohol', 'Final_Banding', 2))
print(check_band_perc(s5_tried_alcohol, 'Final_Banding', 's5_tried_alcohol', 'Normal'))
print(check_band_perc(s5_tried_alcohol, 'Final_Banding', 's5_tried_alcohol', 'Abnormal'))



s5_alcohol_freq_12mo = DV1[['s5_alcohol_freq_12mo', 'Final_Banding', 'Cohort_ID']]
s5_alcohol_freq_12mo_0 = s5_alcohol_freq_12mo[~s5_alcohol_freq_12mo['Final_Banding'].str.contains('Normal')]
tpfreq3 = s5_alcohol_freq_12mo_0.groupby(['s5_alcohol_freq_12mo', 'Final_Banding']).size()
tpfreq3.plot.bar('s5_alcohol_freq_12mo','Final_Banding')

print(check_score_perc(s5_alcohol_freq_12mo, 's5_alcohol_freq_12mo', 'Final_Banding', 0))
print(check_score_perc(s5_alcohol_freq_12mo, 's5_alcohol_freq_12mo', 'Final_Banding', 1))
print(check_score_perc(s5_alcohol_freq_12mo, 's5_alcohol_freq_12mo', 'Final_Banding', 2))
print(check_score_perc(s5_alcohol_freq_12mo, 's5_alcohol_freq_12mo', 'Final_Banding', 3))
print(check_score_perc(s5_alcohol_freq_12mo, 's5_alcohol_freq_12mo', 'Final_Banding', 4))
print(check_score_perc(s5_alcohol_freq_12mo, 's5_alcohol_freq_12mo', 'Final_Banding', 5))
print(check_band_perc(s5_alcohol_freq_12mo, 'Final_Banding', 's5_alcohol_freq_12mo', 'Normal'))
print(check_band_perc(s5_alcohol_freq_12mo, 'Final_Banding', 's5_alcohol_freq_12mo', 'Abnormal'))

DV1['s5_alcohol_freq_4wk'].value_counts()

s5_alcohol_freq_4wk = DV1[['s5_alcohol_freq_4wk', 'Final_Banding', 'Cohort_ID']]
s5_alcohol_freq_4wk_0 = s5_alcohol_freq_4wk[~s5_alcohol_freq_4wk['Final_Banding'].str.contains('Normal')]
tpfreq4 = s5_alcohol_freq_4wk_0.groupby(['s5_alcohol_freq_4wk', 'Final_Banding']).size()
tpfreq4.plot.bar('s5_alcohol_freq_4wk','Final_Banding')

print(check_score_perc(s5_alcohol_freq_4wk, 's5_alcohol_freq_4wk', 'Final_Banding', 0))
print(check_score_perc(s5_alcohol_freq_4wk, 's5_alcohol_freq_4wk', 'Final_Banding', 1))
print(check_score_perc(s5_alcohol_freq_4wk, 's5_alcohol_freq_4wk', 'Final_Banding', 2))
print(check_score_perc(s5_alcohol_freq_4wk, 's5_alcohol_freq_4wk', 'Final_Banding', 3))
print(check_score_perc(s5_alcohol_freq_4wk, 's5_alcohol_freq_4wk', 'Final_Banding', 4))
print(check_score_perc(s5_alcohol_freq_4wk, 's5_alcohol_freq_4wk', 'Final_Banding', 5))
print(check_score_perc(s5_alcohol_freq_4wk, 's5_alcohol_freq_4wk', 'Final_Banding', 6))

print(check_band_perc(s5_alcohol_freq_4wk, 'Final_Banding', 's5_alcohol_freq_4wk', 'Normal'))
print(check_band_perc(s5_alcohol_freq_4wk, 'Final_Banding', 's5_alcohol_freq_4wk', 'Abnormal'))

"""More than 5 drinks at a time"""

heavy_drinking = DV1[['heavy_drinking', 'Final_Banding', 'Cohort_ID']]
heavy_drinking_0 = heavy_drinking[~heavy_drinking['Final_Banding'].str.contains('Normal')]
tpfreq5 = heavy_drinking_0.groupby(['heavy_drinking', 'Final_Banding']).size()
tpfreq5.plot.bar('heavy_drinking','Final_Banding')

print(check_score_perc(heavy_drinking, 'heavy_drinking', 'Final_Banding', 1))
print(check_score_perc(heavy_drinking, 'heavy_drinking', 'Final_Banding', 2))

print(check_band_perc(heavy_drinking, 'Final_Banding', 'heavy_drinking', 'Normal'))
print(check_band_perc(heavy_drinking, 'Final_Banding', 'heavy_drinking', 'Abnormal'))

s6_Ever_Alcoholic_Drink = DV1[['s6_Ever_Alcoholic_Drink', 'Final_Banding', 'Cohort_ID']]
s6_Ever_Alcoholic_Drink_0 = s6_Ever_Alcoholic_Drink[~s6_Ever_Alcoholic_Drink['Final_Banding'].str.contains('Normal')]
tpfreq6 = s6_Ever_Alcoholic_Drink_0.groupby(['s6_Ever_Alcoholic_Drink', 'Final_Banding']).size()
tpfreq6.plot.bar('s6_Ever_Alcoholic_Drink','Final_Banding')

print(check_score_perc(s6_Ever_Alcoholic_Drink, 's6_Ever_Alcoholic_Drink', 'Final_Banding', 1))
print(check_score_perc(s6_Ever_Alcoholic_Drink, 's6_Ever_Alcoholic_Drink', 'Final_Banding', 2))

print(check_band_perc(s6_Ever_Alcoholic_Drink, 'Final_Banding', 's6_Ever_Alcoholic_Drink', 'Normal'))
print(check_band_perc(s6_Ever_Alcoholic_Drink, 'Final_Banding', 's6_Ever_Alcoholic_Drink', 'Abnormal'))

s6_AlcoholFreq_12mo = DV1[['s6_AlcoholFreq_12mo', 'Final_Banding', 'Cohort_ID']]
s6_AlcoholFreq_12mo_0 = s6_AlcoholFreq_12mo[~s6_AlcoholFreq_12mo['Final_Banding'].str.contains('Normal')]
tpfreq7 = s6_AlcoholFreq_12mo_0.groupby(['s6_AlcoholFreq_12mo', 'Final_Banding']).size()
tpfreq7.plot.bar('s6_AlcoholFreq_12mo','Final_Banding')

print(check_score_perc(s6_AlcoholFreq_12mo, 's6_AlcoholFreq_12mo', 'Final_Banding', 1))
print(check_score_perc(s6_AlcoholFreq_12mo, 's6_AlcoholFreq_12mo', 'Final_Banding', 2))

print(check_band_perc(s6_AlcoholFreq_12mo, 'Final_Banding', 's6_AlcoholFreq_12mo', 'Normal'))
print(check_band_perc(s6_AlcoholFreq_12mo, 'Final_Banding', 's6_AlcoholFreq_12mo', 'Abnormal'))

s6_Ever_5plus_Alcohol = DV1[['s6_Ever_5plus_Alcohol', 'Final_Banding', 'Cohort_ID']]
s6_Ever_5plus_Alcohol_0 = s6_Ever_5plus_Alcohol[~s6_Ever_5plus_Alcohol['Final_Banding'].str.contains('Normal')]
tpfreq8 = s6_Ever_5plus_Alcohol_0.groupby(['s6_Ever_5plus_Alcohol', 'Final_Banding']).size()
tpfreq8.plot.bar('s6_Ever_5plus_Alcohol','Final_Banding')

print(check_score_perc(s6_Ever_5plus_Alcohol, 's6_Ever_5plus_Alcohol', 'Final_Banding', 1))
print(check_score_perc(s6_Ever_5plus_Alcohol, 's6_Ever_5plus_Alcohol', 'Final_Banding', 2))

print(check_band_perc(s6_Ever_5plus_Alcohol, 'Final_Banding', 's6_Ever_5plus_Alcohol', 'Normal'))
print(check_band_perc(s6_Ever_5plus_Alcohol, 'Final_Banding', 's6_Ever_5plus_Alcohol', 'Abnormal'))

s6_AlcoholFreq_5plus_12mo = DV1[['s6_AlcoholFreq_5plus_12mo', 'Final_Banding', 'Cohort_ID']]
s6_AlcoholFreq_5plus_12mo_0 = s6_AlcoholFreq_5plus_12mo[~s6_AlcoholFreq_5plus_12mo['Final_Banding'].str.contains('Normal')]
tpfreq9 = s6_AlcoholFreq_5plus_12mo_0.groupby(['s6_AlcoholFreq_5plus_12mo', 'Final_Banding']).size()
tpfreq9.plot.bar('s6_AlcoholFreq_5plus_12mo','Final_Banding', color={'grey'})

print(check_score_perc(s6_AlcoholFreq_5plus_12mo, 's6_AlcoholFreq_5plus_12mo', 'Final_Banding', 1))
print(check_score_perc(s6_AlcoholFreq_5plus_12mo, 's6_AlcoholFreq_5plus_12mo', 'Final_Banding', 2))

print(check_band_perc(s6_AlcoholFreq_5plus_12mo, 'Final_Banding', 's6_AlcoholFreq_5plus_12mo', 'Normal'))
print(check_band_perc(s6_AlcoholFreq_5plus_12mo, 'Final_Banding', 's6_AlcoholFreq_5plus_12mo', 'Abnormal'))

s6_Drug_Cannabis = DV1[['s6_Drug_Cannabis', 'Final_Banding', 'Cohort_ID']]
s6_Drug_Cannabis_0 = s6_Drug_Cannabis[~s6_Drug_Cannabis['Final_Banding'].str.contains('Normal')]
tpfreq10 = s6_Drug_Cannabis_0.groupby(['s6_Drug_Cannabis', 'Final_Banding']).size()
tpfreq10.plot.bar('s6_Drug_Cannabis','Final_Banding')

print(check_score_perc(s6_Drug_Cannabis, 's6_Drug_Cannabis', 'Final_Banding', 1))
print(check_score_perc(s6_Drug_Cannabis, 's6_Drug_Cannabis', 'Final_Banding', 2))

print(check_band_perc(s6_Drug_Cannabis, 'Final_Banding', 's6_Drug_Cannabis', 'Normal'))
print(check_band_perc(s6_Drug_Cannabis, 'Final_Banding', 's6_Drug_Cannabis', 'Abnormal'))

"""Age-17"""

s7_Vaping_Status = DV1[['s7_Vaping_Status', 'Final_Banding', 'Cohort_ID']]
s7_Vaping_Status_0 = s7_Vaping_Status[~s7_Vaping_Status['Final_Banding'].str.contains('Normal')]
tpfreq11 = s7_Vaping_Status_0.groupby(['s7_Vaping_Status', 'Final_Banding']).size()
tpfreq11.plot.bar('s7_Vaping_Status','Final_Banding', color={'grey'})

print(check_score_perc(s7_Vaping_Status, 's7_Vaping_Status', 'Final_Banding', 1))
print(check_score_perc(s7_Vaping_Status, 's7_Vaping_Status', 'Final_Banding', 2))

print(check_band_perc(s7_Vaping_Status, 'Final_Banding', 's7_Vaping_Status', 'Normal'))
print(check_band_perc(s7_Vaping_Status, 'Final_Banding', 's7_Vaping_Status', 'Abnormal'))

s7_Ever_Alcoholic_Drink = DV1[['s7_Ever_Alcoholic_Drink', 'Final_Banding', 'Cohort_ID']]
s7_Ever_Alcoholic_Drink_0 = s7_Ever_Alcoholic_Drink[~s7_Ever_Alcoholic_Drink['Final_Banding'].str.contains('Normal')]
tpfreq12 = s7_Ever_Alcoholic_Drink_0.groupby(['s7_Ever_Alcoholic_Drink', 'Final_Banding']).size()
tpfreq12.plot.bar('s7_Ever_Alcoholic_Drink','Final_Banding', color={'grey'})

print(check_score_perc(s7_Ever_Alcoholic_Drink, 's7_Ever_Alcoholic_Drink', 'Final_Banding', 1))
print(check_score_perc(s7_Ever_Alcoholic_Drink, 's7_Ever_Alcoholic_Drink', 'Final_Banding', 2))

print(check_band_perc(s7_Ever_Alcoholic_Drink, 'Final_Banding', 's7_Ever_Alcoholic_Drink', 'Normal'))
print(check_band_perc(s7_Ever_Alcoholic_Drink, 'Final_Banding', 's7_Ever_Alcoholic_Drink', 'Abnormal'))

s7_AlcoholFreq_12mo = DV1[['s7_AlcoholFreq_12mo', 'Final_Banding', 'Cohort_ID']]
s7_AlcoholFreq_12mo_0 = s7_AlcoholFreq_12mo[~s7_AlcoholFreq_12mo['Final_Banding'].str.contains('Normal')]
tpfreq13 = s7_AlcoholFreq_12mo_0.groupby(['s7_AlcoholFreq_12mo', 'Final_Banding']).size()
tpfreq13.plot.bar('s7_AlcoholFreq_12mo','Final_Banding')

print(check_score_perc(s7_AlcoholFreq_12mo, 's7_AlcoholFreq_12mo', 'Final_Banding', 1))
print(check_score_perc(s7_AlcoholFreq_12mo, 's7_AlcoholFreq_12mo', 'Final_Banding', 2))

print(check_band_perc(s7_AlcoholFreq_12mo, 'Final_Banding', 's7_AlcoholFreq_12mo', 'Normal'))
print(check_band_perc(s7_AlcoholFreq_12mo, 'Final_Banding', 's7_AlcoholFreq_12mo', 'Abnormal'))

s7_Ever_5plus_Alcohol = DV1[['s7_Ever_5plus_Alcohol', 'Final_Banding', 'Cohort_ID']]
s7_Ever_5plus_Alcohol_0 = s7_Ever_5plus_Alcohol[~s7_Ever_5plus_Alcohol['Final_Banding'].str.contains('Normal')]
tpfreq14 = s7_Ever_5plus_Alcohol_0.groupby(['s7_Ever_5plus_Alcohol', 'Final_Banding']).size()
tpfreq14.plot.bar('s7_Ever_5plus_Alcohol','Final_Banding')

print(check_score_perc(s7_Ever_5plus_Alcohol, 's7_Ever_5plus_Alcohol', 'Final_Banding', 1))
print(check_score_perc(s7_Ever_5plus_Alcohol, 's7_Ever_5plus_Alcohol', 'Final_Banding', 2))

print(check_band_perc(s7_Ever_5plus_Alcohol, 'Final_Banding', 's7_Ever_5plus_Alcohol', 'Normal'))
print(check_band_perc(s7_Ever_5plus_Alcohol, 'Final_Banding', 's7_Ever_5plus_Alcohol', 'Abnormal'))

s7_AlcoholFreq_5plus_12mo = DV1[['s7_AlcoholFreq_5plus_12mo', 'Final_Banding', 'Cohort_ID']]
s7_AlcoholFreq_5plus_12mo_0 = s7_AlcoholFreq_5plus_12mo[~s7_AlcoholFreq_5plus_12mo['Final_Banding'].str.contains('Normal')]
tpfreq15 = s7_AlcoholFreq_5plus_12mo_0.groupby(['s7_AlcoholFreq_5plus_12mo', 'Final_Banding']).size()
tpfreq15.plot.bar('s7_AlcoholFreq_5plus_12mo','Final_Banding')

print(check_score_perc(s7_AlcoholFreq_5plus_12mo, 's7_AlcoholFreq_5plus_12mo', 'Final_Banding', 1))
print(check_score_perc(s7_AlcoholFreq_5plus_12mo, 's7_AlcoholFreq_5plus_12mo', 'Final_Banding', 2))

print(check_band_perc(s7_AlcoholFreq_5plus_12mo, 'Final_Banding', 's7_AlcoholFreq_5plus_12mo', 'Normal'))
print(check_band_perc(s7_AlcoholFreq_5plus_12mo, 'Final_Banding', 's7_AlcoholFreq_5plus_12mo', 'Abnormal'))

s7_PastYear_Drug = DV1[['s7_PastYear_Drug', 'Final_Banding', 'Cohort_ID']]
s7_PastYear_Drug_0 = s7_PastYear_Drug[~s7_PastYear_Drug['Final_Banding'].str.contains('Normal')]
tpfreq16 = s7_PastYear_Drug_0.groupby(['s7_PastYear_Drug', 'Final_Banding']).size()
tpfreq16.plot.bar('s7_PastYear_Drug','Final_Banding')

#print(check_score_perc(s7_PastYear_Drug, 's7_PastYear_Drug', 'Final_Banding', 1))
#print(check_score_perc(s7_PastYear_Drug, 's7_PastYear_Drug', 'Final_Banding', 2))
#print(check_band_perc(s7_PastYear_Drug, 'Final_Banding', 's7_PastYear_Drug', 'Normal'))
#print(check_band_perc(s7_PastYear_Drug, 'Final_Banding', 's7_PastYear_Drug', 'Abnormal'))

s7_Ever_Taken_Cannabis = DV1[['s7_Ever_Taken_Cannabis', 'Final_Banding', 'Cohort_ID']]
s7_Ever_Taken_Cannabis_0 = s7_Ever_Taken_Cannabis[~s7_Ever_Taken_Cannabis['Final_Banding'].str.contains('Normal')]
tpfreq17 = s7_Ever_Taken_Cannabis_0.groupby(['s7_Ever_Taken_Cannabis', 'Final_Banding']).size()
tpfreq17.plot.bar('s7_Ever_Taken_Cannabis','Final_Banding')

s7_Ever_Taken_Cocaine = DV1[['s7_Ever_Taken_Cocaine', 'Final_Banding', 'Cohort_ID']]
s7_Ever_Taken_Cocaine_0 = s7_Ever_Taken_Cocaine[~s7_Ever_Taken_Cocaine['Final_Banding'].str.contains('Normal')]
tpfreq18 = s7_Ever_Taken_Cocaine_0.groupby(['s7_Ever_Taken_Cocaine', 'Final_Banding']).size()
tpfreq18.plot.bar('s7_Ever_Taken_Cocaine','Final_Banding')

s7_Ever_Taken_Psychoactive_Substances = DV1[['s7_Ever_Taken_Psychoactive_Substances', 'Final_Banding', 'Cohort_ID']]
s7_Ever_Taken_Psychoactive_Substances_0 = s7_Ever_Taken_Psychoactive_Substances[~s7_Ever_Taken_Psychoactive_Substances['Final_Banding'].str.contains('Normal')]
tpfreq19 = s7_Ever_Taken_Psychoactive_Substances_0.groupby(['s7_Ever_Taken_Psychoactive_Substances', 'Final_Banding']).size()
tpfreq19.plot.bar('s7_Ever_Taken_Psychoactive_Substances','Final_Banding')

s7_Ever_Taken_Acid = DV1[['s7_Ever_Taken_Acid', 'Final_Banding', 'Cohort_ID']]
s7_Ever_Taken_Acid_0 = s7_Ever_Taken_Acid[~s7_Ever_Taken_Acid['Final_Banding'].str.contains('Normal')]
tpfreq20 = s7_Ever_Taken_Acid_0.groupby(['s7_Ever_Taken_Acid', 'Final_Banding']).size()
tpfreq20.plot.bar('s7_Ever_Taken_Acid','Final_Banding')

categorical_columns = ['s5_friends_smoke','s5_tried_cigarette', 's5_friends_drink', 's5_tried_alcohol',
        'heavy_drinking','s6_SmokeFreq_Cigarettes', 's6_SmokeFreq_E_Cigarettes',
       's6_SmokeFreq_Friends_Cigarettes', 's6_Ever_Alcoholic_Drink',
       's6_Ever_5plus_Alcohol', 's6_AlcoholFreq_5plus_12mo','s6_Friends_Drink_Alcohol', 's6_Drug_Cannabis',
       's6_Drug_Other_Illegal', 's6_SmokeFreq_Cannabis','s6_Friends_Illegal_Drugs',
	   's7_Smoking_Status', 's7_Vaping_Status', 's7_Ever_Alcoholic_Drink',
       's7_Age_First_Alcoholic_Drink', 's7_Ever_5plus_Alcohol',
       's7_AlcoholFreq_5plus_12mo', 's7_Ever_Taken_Cannabis', 's7_Ever_Taken_Cocaine', 's7_Ever_Taken_Acid',
       's7_Ever_Taken_Ecstasy', 's7_Ever_Taken_Speed','s7_Ever_Taken_Semeron', 's7_Ever_Taken_Ketamine',
       's7_Ever_Taken_Mephedrone','s7_Ever_Taken_Psychoactive_Substances','Final_Banding']
for column in categorical_columns:
    contingency_table = pd.crosstab(DV1[column], DV1['Overall_Banding'])
    chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)
    print(f"Chi-Square Test for {column} vs Final_Banding:")
    print("Chi-Square Statistic:", chi2_stat)
    print("Degree of Freedom:", dof)
    print("P-Value:", p_value)
    print("\nContingency Table:")
    print(contingency_table)
    print("-------------------------")

def cramers_v(confusion_matrix):
    chi2 = chi2_contingency(confusion_matrix)[0]
    n = confusion_matrix.sum()
    phi2 = chi2 / n
    r, k = confusion_matrix.shape
    phi2corr = max(0, phi2 - ((k - 1) * (r - 1)) / (n - 1))
    r_corr = r - ((r - 1) ** 2) / (n - 1)
    k_corr = k - ((k - 1) ** 2) / (n - 1)
    return np.sqrt(phi2corr / min((k_corr - 1), (r_corr - 1)))

for column in categorical_columns:
    contingency_table = pd.crosstab(DV1[column], DV1['Overall_Banding'])
    cramers_value = cramers_v(contingency_table.values)
    print(f"Cramer's V for {column} vs Final_Banding:")
    print("Cramer's V:", cramers_value)
    print("\nContingency Table:")
    print(contingency_table)
    print("-------------------------")

"""Machine Learning"""

s7_alcohol_cm_conditions = [

       (all_cm['s7_Ever_Alcoholic_Drink'] == 1)&
    (all_cm['s7_AlcoholFreq_12mo'] <=3) &
    (all_cm['s7_AlcoholFreq_4wk'] <= 3)&
    (all_cm['s7_Ever_5plus_Alcohol']==1)  &
    (all_cm['s7_AlcoholFreq_5plus_12mo']<3),

    (all_cm['s7_Ever_Alcoholic_Drink'] == 1)&
    (all_cm['s7_AlcoholFreq_12mo'] >3) &
    (all_cm['s7_AlcoholFreq_4wk'] > 3)&
    (all_cm['s7_Ever_5plus_Alcohol']==1 ) &
    (all_cm['s7_AlcoholFreq_5plus_12mo']>3)
]
s7_alcohol_banding = ['Average', 'Abnormal']

# Apply np.select to assign categories
DV1['Banding_alc'] = np.select(s7_alcohol_cm_conditions, s7_alcohol_banding, default='Normal')

all_cm['smok_score']=all_cm[['s7_Smoking_Status','s7_Vaping_Status']].sum(axis=1,skipna=True)
s7_smok_cond = [((all_cm['smok_score']>=0.0) & (all_cm['smok_score'] <3.0)),
                ((all_cm['smok_score']>=3.0) & (all_cm['smok_score'] <6.0)),
                 (all_cm['smok_score']>=6.0 )]
s7_smok_band =['Normal','Average','Abnormal']
DV1['Banding_smo']=np.select(s7_smok_cond,s7_smok_band)

s7_drug_cond =[((all_cm['s7_PastYear_Drug']>1)&(all_cm['s7_PastYear_Drug']<=4)),
               ((all_cm['s7_PastYear_Drug']>=5))]
s7_drug_band =['Borderline','Abnormal']
DV1['drug_band']=np.select(s7_drug_cond,s7_drug_band,default='Normal')

def determine_overall_banding(row):
    abnormal_count = 0
    if row['Banding_alc'] == 'Abnormal':
        abnormal_count += 1
    if row['Banding_smo'] == 'Abnormal':
        abnormal_count += 1
    if row['drug_band'] == 'Abnormal':
        abnormal_count += 1

    if abnormal_count >= 2:
        return 'Abnormal'
    else:
        return 'Normal'

DV1['Overall_Banding'] = DV1.apply(determine_overall_banding, axis=1)

DV1.columns

DV1['Overall_Banding'].value_counts()

DV1.head()

DV_copy = DV1.copy()

DV_copy=DV_copy.drop(['SDQ_Banding', 'K6_Banding', 's7_Doctor_Diagnosed_Depression_Anxiety', 'self_harm_banding','s7_Smoking_Status', 's7_Vaping_Status', 's7_Ever_Alcoholic_Drink', 's7_Age_First_Alcoholic_Drink', 's7_AlcoholFreq_12mo', 's7_AlcoholFreq_4wk', 's7_Ever_5plus_Alcohol', 's7_AlcoholFreq_5plus_12mo', 's7_Ever_Taken_Cannabis', 's7_Ever_Taken_Cocaine', 's7_Ever_Taken_Acid', 's7_Ever_Taken_Ecstasy', 's7_Ever_Taken_Speed', 's7_Ever_Taken_Semeron',
       's7_Ever_Taken_Ketamine', 's7_Ever_Taken_Mephedrone', 's7_Ever_Taken_Psychoactive_Substances', 's7_PastYear_Drug', 'Banding_alc', 'Banding_smo', 'drug_band'],axis=1)

DV_copy.columns

def cleaner(df, cleaner):
    if cleaner == 'KNNImputer':
        df_0 = df.drop(['Cohort_ID', 'Overall_Banding'], axis=1)
        knn = KNNImputer(n_neighbors=1)
        trans = pd.DataFrame(knn.fit_transform(df_0), columns=df_0.columns)
        trans['Cohort_ID'], trans['Overall_Banding'] = df['Cohort_ID'], df['Overall_Banding']
    elif cleaner == 'Mode':
        trans = df.apply(lambda x: x.fillna(x.value_counts().index[0]))
    return trans

DV_copy['Final_Banding'] = DV_copy['Final_Banding'].replace(['Normal', 'Abnormal'], [0, 1])
DV_copy['Overall_Banding'] = DV_copy['Overall_Banding'].replace(['Normal', 'Abnormal'], [0, 1])

clean_final_data = cleaner(DV_copy, 'KNNImputer')

clean_final_data.head()

# Standardising Nominal & Ordinal Data
ordinal = clean_final_data.drop(['Cohort_ID'], axis=1)

# Ordinal Encoding
ord = OrdinalEncoder()
ord_code = pd.DataFrame(ord.fit_transform(ordinal), columns=ordinal.columns)

all_train, all_test = train_test_split(ordinal, test_size=0.30, random_state=1)
all_train, all_test = all_train.reset_index(drop=True), all_test.reset_index(drop=True)

# define dataset
Xk = all_train.copy()
yk = Xk.pop('Overall_Banding')

oversample = SMOTEN(random_state=0)
nXk, nyk = oversample.fit_resample(Xk, yk)

nXk['Overall_Banding'] = nyk
over_data = nXk.copy()

#Testing Data - #test_knn_randover, #test_mode_randover, #test_knn_SMOTEover, #test_mode_SMOTEover
testX = over_data.copy() #over_data.copy()
testy = testX.pop('Overall_Banding')

# Model Tester Function
def Model_Tester(X, y, r, model):
    # Repeated K-fold cross-validation
    cv = RepeatedKFold(n_splits=5, n_repeats=r, random_state=1)

    # Create Model
    if model == 'NB':
        model = GaussianNB()
    elif model == 'knn':
        model = KNeighborsClassifier(n_neighbors=3)
    elif model == 'dt':
        model = DecisionTreeClassifier()
    elif model == 'rf':
        model = RandomForestClassifier(class_weight='balanced')
    elif model == 'lr':
        model = LogisticRegression(class_weight='balanced')

    # Confusion_Matrix_Scorer
    def confusion_matrix_scorer(clf, X, y):
        y_pred = clf.predict(X)
        cm = confusion_matrix(y, y_pred)

        return {'tn': cm[0, 0], 'fp': cm[0, 1],
                'fn': cm[1, 0], 'tp': cm[1, 1]}

    # Evaluate Model
    Acc = cross_validate(model, X, y, scoring='accuracy', cv=cv, n_jobs=1)
    CM = cross_validate(model, X, y, scoring=confusion_matrix_scorer, cv=cv, n_jobs=1)
    Pre = cross_validate(model, X, y, scoring='precision', cv=cv, n_jobs=1)
    Recall = cross_validate(model, X, y, scoring='recall', cv=cv, n_jobs=1)
    F1 = cross_validate(model, X, y, scoring='f1', cv=cv, n_jobs=1)
    Roc = cross_validate(model, X, y, scoring='roc_auc', cv=cv, n_jobs=1)

    # Heatmap
    df = pd.DataFrame.from_dict(CM)
    df = df.drop(['fit_time', 'score_time'], axis=1)
    dic = {}
    for col in df:
        dic[col] = df[col].mean()
    array = np.array(list(dic.values()))
    narray = array.reshape(2, 2)
    sns.heatmap(narray, annot=True, cmap='YlGnBu', fmt='g')

    # Printing Results
    print(dic)
    print('Accuracy: {}'.format(mean(Acc['test_score'])))
    print('Precision: {}'.format(mean(Pre['test_score'])))
    print('Recall: {}'.format(mean(Recall['test_score'])))
    print('F1: {}'.format(mean(F1['test_score'])))
    print('Roc AUC Score: {}'.format(mean(Roc['test_score'])))

    meanacc = (mean(Acc['test_score']))
    meanf1 = (mean(F1['test_score']))
    return meanacc, meanf1

# Testing Logistic Regression Model
lra, lrf = Model_Tester(testX, testy, 1, 'lr')

nba, nbf = Model_Tester(testX, testy, 1, 'NB')

dta, dtf = Model_Tester(testX, testy, 1, 'dt')

knna, knnf = Model_Tester(testX, testy, 1, 'knn')

rfa, rff = Model_Tester(testX, testy, 1, 'rf')

model_comp1 = [['Accuracy', 0.9430526315789473, 0.7833684210526315, 0.7527368421052631, 0.8503157894736843, 0.7412631578947369],
               ['Precision', 0.9712824761675078, 0.7578786109999134, 0.717809856676067, 0.8172917296755173, 0.7384079157697671],
               ['Recall', 0.9060212171750528, 0.8353613614376417, 0.8330274267466141, 0.7912566164464421, 0.7511237519620913],
               ['F1 Score', 0.9352636051073036, 0.794375715830918, 0.7710840494579847, 0.6934509225408527, 0.7445680304200692],
               ['ROC AUC Score', 0.8929666387718489, 0.7822572272347685, 0.8189214712776176, 0.7327031303469838, 0.6899686530782339]]

model_comp_df = pd.DataFrame(model_comp1)
model_comp_df.columns = ['Score', 'Random Forest', 'Decision Tree', 'K-Nearest Neighbour', 'Naive Bayes', 'Logistic Regression']

ax = model_comp_df.set_index('Score').T.plot.line(figsize=(12, 8), marker='o')
plt.title('Classifier Model Performance Comparison', fontsize=18)
plt.xlabel('Models', fontsize=14)
plt.ylabel('Score', fontsize=14)
plt.xticks(rotation=45)
plt.legend(loc='lower right')

def random_forest(X_train, y_train):

  #models and cross val
  cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1)
  model = RandomForestClassifier(random_state=1, class_weight='balanced')

  #fit model
  trained_model = model.fit(X_train, y_train)

  #Confusion_Matrix_Scorer
  def confusion_matrix_scorer(clf, X, y):
    y_pred = clf.predict(X)
    cm = confusion_matrix(y, y_pred)

    return {'tn': cm[0, 0], 'fp': cm[0, 1],
            'fn': cm[1, 0], 'tp': cm[1, 1]}


  #Evaluate Model
  scoring = {'acc':'accuracy', 'pre':'precision', 'recall':'recall', 'F1':'f1', 'RA':'roc_auc'}
  scores = cross_validate(model, X_train, y_train, scoring=scoring, cv=cv, n_jobs=1)
  CM = cross_validate(model, X_train, y_train, scoring=confusion_matrix_scorer, cv=cv, n_jobs=1)

  #Heatmap
  df = pd.DataFrame.from_dict(CM)
  df = df.drop(['fit_time', 'score_time'], axis=1)
  dic = {}
  for col in df:
    dic[col] = df[col].mean()
  array = np.array(list(dic.values()))
  narray = array.reshape(2, 2)
  sns.heatmap(narray, annot=True, cmap='YlGnBu', fmt='g')

  #Printing Results
  print('Accuracy: {}'.format(mean(scores['test_acc'])))
  print('Precision: {}'.format(mean(scores['test_pre'])))
  print('Recall: {}'.format(mean(scores['test_recall'])))
  print('F1: {}'.format(mean(scores['test_F1'])))
  print('Roc AUC Score: {}'.format(mean(scores['test_RA'])))

  return trained_model

def shap_values(X_test, model):
  #SHAP values (Feature importance)
  shap.initjs()
  explainer = shap.TreeExplainer(model)
  shap_values = explainer.shap_values(X_test)
  shap_obj0 = explainer(X_test)

  shap_obj = copy.deepcopy(shap_obj0)
  shap_obj.values = shap_obj.values[:,:,1]
  shap_obj.base_values = shap_obj.base_values[:,1]
  return shap_obj, shap_values

X_train = over_data.copy()
y_train = X_train.pop('Overall_Banding')

X_test = all_test.copy()
y_test = X_test.pop('Overall_Banding')

rf_fit_model = random_forest(X_train, y_train)

All_shapobj, All_shapvalues = shap_values(X_test, rf_fit_model) #10 Minutes

feature_colors = ['red', 'green', 'blue', 'purple']  # Add more colors as needed
shap.summary_plot(All_shapobj, plot_type='bar', color='paleturquoise')

shap.summary_plot(All_shapobj)

for colname in X_test:
    shap.dependence_plot(colname, All_shapvalues[1], X_test, interaction_index=None)

